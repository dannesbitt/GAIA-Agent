{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1oAna1weK/7DxB6zBKpeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dannesbitt/GAIA-Agent/blob/main/GAIA_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langgraph langchain_openai langchain_huggingface google-cloud-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq8_eyzKtl8t",
        "outputId": "815e0835-d9f1-4f07-c129-0df0174157f8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/334.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/334.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "IZgLOVDusN0Q",
        "outputId": "6097f882-01bb-428d-9978-2a2d1b8702d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: On June 6, 2023, an article by Carolyn Collins Petersen was published in Universe Today. This article mentions a team that produced a paper about their observations, linked at the bottom of the article. Find this paper. Under what NASA award number was the work performed by R. G. Arendt supported by?\n",
            "FileID:  None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'ChatCompletionMessageToolCall' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-05cd1b7c595a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"needs_tool_call\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m }\n\u001b[0;32m--> 265\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final State:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2794\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2795\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2796\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2431\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2434\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-05cd1b7c595a>\u001b[0m in \u001b[0;36mtool_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0massistant_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtool_call\u001b[0m \u001b[0;32min\u001b[0m \u001b[0massistant_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_tool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         state['messages'].append({\n\u001b[1;32m    222\u001b[0m             \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"tool\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-05cd1b7c595a>\u001b[0m in \u001b[0;36mexecute_tool\u001b[0;34m(tool_call)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Dummy tool execution function (replace with actual tools if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_tool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtool_call\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"function\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"get_weather\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"It's sunny today.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Tool not found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletionMessageToolCall' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "from typing import TypedDict, List\n",
        "from openai import OpenAI\n",
        "from langgraph.graph import Graph, END\n",
        "from google.colab import userdata\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "from google.cloud import speech_v1p1beta1 as speech\n",
        "\n",
        "# Set up OpenAI client\n",
        "OPEN_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPEN_API_KEY)\n",
        "\n",
        "# Set up YouTube API key\n",
        "YOUTUBE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "google_key =  YOUTUBE_API_KEY\n",
        "\n",
        "# Set up Google Cloud credentials for Speech-to-Text\n",
        "#google_key = userdata.get('GOOGLE_CLOUD_KEY')\n",
        "#if google_key:\n",
        "#    with open('/content/key.json', 'w') as f:\n",
        "#        f.write(google_key)\n",
        "#    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/key.json'\n",
        "#else:\n",
        "#    print(\"Google Cloud key not found in userdata. Please upload the service account key file to '/content/key.json' manually.\")\n",
        "\n",
        "# Define the state structure\n",
        "class State(TypedDict):\n",
        "    messages: List[dict]\n",
        "    tool_calls: List[dict]\n",
        "    final_response: str\n",
        "    needs_tool_call: bool\n",
        "\n",
        "# Define available tools (optional, included for flexibility)\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get the current weather\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "# Dummy tool execution function (replace with actual tools if needed)\n",
        "def execute_tool(tool_call):\n",
        "    if tool_call[\"function\"][\"name\"] == \"get_weather\":\n",
        "        return \"It's sunny today.\"\n",
        "    return \"Tool not found.\"\n",
        "\n",
        "# Helper function to fetch task files\n",
        "def fetch_task_files(task_id):\n",
        "    \"\"\"Fetches files associated with the task_id from the API.\"\"\"\n",
        "    url = f\"https://agents-course-unit4-scoring.hf.space/files/{task_id}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        files_data = response.json()\n",
        "        file_contents = {file[\"filename\"]: file[\"content\"] for file in files_data}\n",
        "        return file_contents\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching files for task_id {task_id}: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Helper function to extract YouTube video ID from a URL\n",
        "def extract_youtube_id(url):\n",
        "    \"\"\"Extracts the video ID from a YouTube URL.\"\"\"\n",
        "    parsed = urlparse(url)\n",
        "    if parsed.netloc == 'www.youtube.com' and parsed.path == '/watch':\n",
        "        query = parse_qs(parsed.query)\n",
        "        return query.get('v', [None])[0]\n",
        "    elif parsed.netloc == 'youtu.be':\n",
        "        return parsed.path[1:] if parsed.path else None\n",
        "    return None\n",
        "\n",
        "# Helper function to parse SBV caption format\n",
        "def parse_sbv(sbv_text):\n",
        "    \"\"\"Parses SBV caption text to extract plain transcript.\"\"\"\n",
        "    blocks = sbv_text.strip().split('\\n\\n')\n",
        "    transcript = []\n",
        "    for block in blocks:\n",
        "        lines = block.split('\\n')\n",
        "        if len(lines) > 1:\n",
        "            transcript.append(' '.join(lines[1:]))\n",
        "    return ' '.join(transcript)\n",
        "\n",
        "# Helper function to fetch YouTube transcript using YouTube Data API v3\n",
        "def fetch_youtube_transcript(video_id, api_key):\n",
        "    \"\"\"Fetches the transcript for a YouTube video using the YouTube Data API v3.\"\"\"\n",
        "    if not api_key:\n",
        "        print(\"YouTube API key not set, cannot fetch transcript.\")\n",
        "        return None\n",
        "    try:\n",
        "        list_url = f'https://www.googleapis.com/youtube/v3/captions?part=snippet&videoId={video_id}&key={api_key}'\n",
        "        list_response = requests.get(list_url).json()\n",
        "        if 'items' not in list_response or not list_response['items']:\n",
        "            return None\n",
        "        caption_id = list_response['items'][0]['id']\n",
        "        download_url = f'https://www.googleapis.com/youtube/v3/captions/{caption_id}?tfmt=sbv&key={api_key}'\n",
        "        sbv_text = requests.get(download_url).text\n",
        "        transcript = parse_sbv(sbv_text)\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching transcript for video {video_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Helper function to download audio file\n",
        "def download_audio(url, save_path):\n",
        "    \"\"\"Downloads an audio file from the given URL to the specified path.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(save_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading audio from {url}: {e}\")\n",
        "\n",
        "# Helper function to transcribe audio using Google Cloud Speech-to-Text\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribes an audio file using Google Cloud Speech-to-Text.\"\"\"\n",
        "    try:\n",
        "        client = speech.SpeechClient()\n",
        "        with open(audio_path, 'rb') as audio_file:\n",
        "            content = audio_file.read()\n",
        "        audio = speech.RecognitionAudio(content=content)\n",
        "        config = speech.RecognitionConfig(\n",
        "            encoding=speech.RecognitionConfig.AudioEncoding.MP3,\n",
        "            sample_rate_hertz=16000,  # Note: Adjust this if the audio file's sample rate differs\n",
        "            language_code='en-US',\n",
        "        )\n",
        "        response = client.recognize(config=config, audio=audio)\n",
        "        transcript = ' '.join([result.alternatives[0].transcript for result in response.results])\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio at {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Define the nodes\n",
        "def input_node(state: State) -> State:\n",
        "    \"\"\"Fetches a question from the API, checks for file_id, YouTube links, and audio files, downloads files and transcripts if present, and constructs the initial user message.\"\"\"\n",
        "    if not state['messages']:\n",
        "        try:\n",
        "            response = requests.get('https://agents-course-unit4-scoring.hf.space/random-question')\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            question = data['question']\n",
        "            print(\"Question:\", question)\n",
        "            file_id = data.get('file_id', None)\n",
        "            print(\"FileID: \", file_id)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching question: {e}\")\n",
        "            question = \"What is the meaning of life?\"\n",
        "            file_id = None\n",
        "\n",
        "        # Construct the user message\n",
        "        user_message = f\"Question: {question}\\n\\n\"\n",
        "        if file_id:\n",
        "            file_contents = fetch_task_files(file_id)\n",
        "            if file_contents:\n",
        "                user_message += \"File contents:\\n\"\n",
        "                for filename, content in file_contents.items():\n",
        "                    user_message += f\"{filename}:\\n{content}\\n\\n\"\n",
        "\n",
        "        # Check for YouTube links in the question\n",
        "        youtube_urls = [url for url in re.findall(r'https?://\\S+', question) if 'youtube.com' in url or 'youtu.be' in url]\n",
        "        if youtube_urls:\n",
        "            video_id = extract_youtube_id(youtube_urls[0])\n",
        "            if video_id:\n",
        "                transcript = fetch_youtube_transcript(video_id, YOUTUBE_API_KEY)\n",
        "                if transcript:\n",
        "                    user_message += f\"\\n\\nTranscript of the YouTube video: {transcript}\"\n",
        "                else:\n",
        "                    user_message += \"\\n\\nTranscript of the YouTube video: Not available\"\n",
        "\n",
        "        # Check for audio file URLs (e.g., MP3) in the question\n",
        "        audio_urls = [url for url in re.findall(r'https?://\\S+', question) if url.lower().endswith('.mp3')]\n",
        "        if audio_urls:\n",
        "            audio_url = audio_urls[0]  # Process the first audio URL only\n",
        "            audio_path = '/content/audio.mp3'\n",
        "            download_audio(audio_url, audio_path)\n",
        "            transcript = transcribe_audio(audio_path)\n",
        "            if transcript:\n",
        "                user_message += f\"\\n\\nTranscript of the audio file: {transcript}\"\n",
        "            else:\n",
        "                user_message += \"\\n\\nTranscript of the audio file: Not available\"\n",
        "\n",
        "        state['messages'].append({\"role\": \"user\", \"content\": user_message})\n",
        "    state['needs_tool_call'] = False\n",
        "    return state\n",
        "\n",
        "def llm_node(state: State) -> State:\n",
        "    \"\"\"Calls the OpenAI LLM with the current messages and processes the response.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=state['messages'],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "    )\n",
        "    assistant_message = response.choices[0].message\n",
        "    state['messages'].append(assistant_message)\n",
        "\n",
        "    if assistant_message.tool_calls:\n",
        "        state['needs_tool_call'] = True\n",
        "    else:\n",
        "        state['final_response'] = assistant_message.content\n",
        "        state['needs_tool_call'] = False\n",
        "    return state\n",
        "\n",
        "def tool_node(state: State) -> State:\n",
        "    \"\"\"Executes tool calls and appends results to messages.\"\"\"\n",
        "    assistant_message = state['messages'][-1]\n",
        "    for tool_call in assistant_message.tool_calls:\n",
        "        result = execute_tool(tool_call)\n",
        "        state['messages'].append({\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": result,\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "        })\n",
        "    return state\n",
        "\n",
        "def output_node(state: State) -> State:\n",
        "    \"\"\"Prints the LLM's response.\"\"\"\n",
        "    print(\"Response:\", state['final_response'])\n",
        "    return state\n",
        "\n",
        "# Create the graph\n",
        "graph = Graph()\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"input\", input_node)\n",
        "graph.add_node(\"llm\", llm_node)\n",
        "graph.add_node(\"tool\", tool_node)\n",
        "graph.add_node(\"output\", output_node)\n",
        "\n",
        "# Define edges\n",
        "graph.add_edge(\"input\", \"llm\")\n",
        "graph.add_conditional_edges(\n",
        "    \"llm\",\n",
        "    lambda state: \"tool\" if state['needs_tool_call'] else \"output\",\n",
        "    {\"tool\": \"tool\", \"output\": \"output\"}\n",
        ")\n",
        "graph.add_edge(\"tool\", \"input\")\n",
        "graph.add_edge(\"output\", END)\n",
        "\n",
        "# Set entry point\n",
        "graph.set_entry_point(\"input\")\n",
        "\n",
        "# Compile the graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run the workflow\n",
        "initial_state = {\n",
        "    \"messages\": [],\n",
        "    \"tool_calls\": [],\n",
        "    \"final_response\": \"\",\n",
        "    \"needs_tool_call\": False\n",
        "}\n",
        "result = app.invoke(initial_state)\n",
        "print(\"Final State:\", result)"
      ]
    }
  ]
}