{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/t2ipg4qupw2O/Sy5zQ4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dannesbitt/GAIA-Agent/blob/main/GAIA_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langgraph langchain_openai langchain_huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq8_eyzKtl8t",
        "outputId": "01e41fcf-4921-4da2-cce8-e2956aba0432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZgLOVDusN0Q",
        "outputId": "de6f501c-b486-4bd6-9b67-f1e0cf727915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Hi, I was out sick from my classes on Friday, so I'm trying to figure out what I need to study for my Calculus mid-term next week. My friend from class sent me an audio recording of Professor Willowbrook giving out the recommended reading for the test, but my headphones are broken :(\n",
            "\n",
            "Could you please listen to the recording for me and tell me the page numbers I'm supposed to go over? I've attached a file called Homework.mp3 that has the recording. Please provide just the page numbers as a comma-delimited list. And please provide the list in ascending order.\n",
            "Response: I'm unable to listen to or process audio files at the moment. However, you can use a transcription service or software to convert the audio recording into text. Once you have the text, I'd be happy to help you extract the page numbers you need. Let me know how else I can assist you!\n",
            "Final State: {'messages': [{'role': 'user', 'content': \"Question: Hi, I was out sick from my classes on Friday, so I'm trying to figure out what I need to study for my Calculus mid-term next week. My friend from class sent me an audio recording of Professor Willowbrook giving out the recommended reading for the test, but my headphones are broken :(\\n\\nCould you please listen to the recording for me and tell me the page numbers I'm supposed to go over? I've attached a file called Homework.mp3 that has the recording. Please provide just the page numbers as a comma-delimited list. And please provide the list in ascending order.\\n\\n\"}, ChatCompletionMessage(content=\"I'm unable to listen to or process audio files at the moment. However, you can use a transcription service or software to convert the audio recording into text. Once you have the text, I'd be happy to help you extract the page numbers you need. Let me know how else I can assist you!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)], 'tool_calls': [], 'final_response': \"I'm unable to listen to or process audio files at the moment. However, you can use a transcription service or software to convert the audio recording into text. Once you have the text, I'd be happy to help you extract the page numbers you need. Let me know how else I can assist you!\", 'needs_tool_call': False}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from typing import TypedDict, List\n",
        "from openai import OpenAI\n",
        "from langgraph.graph import Graph, END\n",
        "from google.colab import userdata\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# Set up OpenAI client\n",
        "OPEN_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPEN_API_KEY)\n",
        "\n",
        "# Set up YouTube API key\n",
        "YOUTUBE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Define the state structure\n",
        "class State(TypedDict):\n",
        "    messages: List[dict]\n",
        "    tool_calls: List[dict]\n",
        "    final_response: str\n",
        "    needs_tool_call: bool\n",
        "\n",
        "# Define available tools (optional, included for flexibility)\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get the current weather\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "# Dummy tool execution function (replace with actual tools if needed)\n",
        "def execute_tool(tool_call):\n",
        "    if tool_call[\"function\"][\"name\"] == \"get_weather\":\n",
        "        return \"It's sunny today.\"\n",
        "    return \"Tool not found.\"\n",
        "\n",
        "# Helper function to fetch task files\n",
        "def fetch_task_files(task_id):\n",
        "    \"\"\"Fetches files associated with the task_id from the API.\"\"\"\n",
        "    url = f\"https://agents-course-unit4-scoring.hf.space/files/{task_id}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        files_data = response.json()\n",
        "        file_contents = {file[\"filename\"]: file[\"content\"] for file in files_data}\n",
        "        return file_contents\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching files for task_id {task_id}: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Helper function to extract YouTube video ID from a URL\n",
        "def extract_youtube_id(url):\n",
        "    \"\"\"Extracts the video ID from a YouTube URL.\"\"\"\n",
        "    parsed = urlparse(url)\n",
        "    if parsed.netloc == 'www.youtube.com' and parsed.path == '/watch':\n",
        "        query = parse_qs(parsed.query)\n",
        "        return query.get('v', [None])[0]\n",
        "    elif parsed.netloc == 'youtu.be':\n",
        "        return parsed.path[1:] if parsed.path else None\n",
        "    return None\n",
        "\n",
        "# Helper function to parse SBV caption format\n",
        "def parse_sbv(sbv_text):\n",
        "    \"\"\"Parses SBV caption text to extract plain transcript.\"\"\"\n",
        "    blocks = sbv_text.strip().split('\\n\\n')\n",
        "    transcript = []\n",
        "    for block in blocks:\n",
        "        lines = block.split('\\n')\n",
        "        if len(lines) > 1:\n",
        "            transcript.append(' '.join(lines[1:]))\n",
        "    return ' '.join(transcript)\n",
        "\n",
        "# Helper function to fetch YouTube transcript using YouTube Data API v3\n",
        "def fetch_youtube_transcript(video_id, api_key):\n",
        "    \"\"\"Fetches the transcript for a YouTube video using the YouTube Data API v3.\"\"\"\n",
        "    if not api_key:\n",
        "        print(\"YouTube API key not set, cannot fetch transcript.\")\n",
        "        return None\n",
        "    try:\n",
        "        # List caption tracks\n",
        "        list_url = f'https://www.googleapis.com/youtube/v3/captions?part=snippet&videoId={video_id}&key={api_key}'\n",
        "        list_response = requests.get(list_url).json()\n",
        "        if 'items' not in list_response or not list_response['items']:\n",
        "            return None\n",
        "        # Select the first caption track\n",
        "        caption_id = list_response['items'][0]['id']\n",
        "        # Download caption in SBV format\n",
        "        download_url = f'https://www.googleapis.com/youtube/v3/captions/{caption_id}?tfmt=sbv&key={api_key}'\n",
        "        sbv_text = requests.get(download_url).text\n",
        "        # Parse SBV to extract text\n",
        "        transcript = parse_sbv(sbv_text)\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching transcript for video {video_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Define the nodes\n",
        "def input_node(state: State) -> State:\n",
        "    \"\"\"Fetches a question from the API, checks for file_id and YouTube links, downloads files and transcripts if present, and constructs the initial user message.\"\"\"\n",
        "    if not state['messages']:\n",
        "        try:\n",
        "            response = requests.get('https://agents-course-unit4-scoring.hf.space/random-question')\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            question = data['question']\n",
        "            print(\"Question:\", question)  # Fixed typo from {question} to question\n",
        "            file_id = data.get('file_id', None)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching question: {e}\")\n",
        "            question = \"What is the meaning of life?\"\n",
        "            file_id = None\n",
        "\n",
        "        # Construct the user message\n",
        "        user_message = f\"Question: {question}\\n\\n\"\n",
        "        if file_id:\n",
        "            file_contents = fetch_task_files(file_id)\n",
        "            if file_contents:\n",
        "                user_message += \"File contents:\\n\"\n",
        "                for filename, content in file_contents.items():\n",
        "                    user_message += f\"{filename}:\\n{content}\\n\\n\"\n",
        "\n",
        "        # Check for YouTube links in the question\n",
        "        youtube_urls = [url for url in re.findall(r'https?://\\S+', question) if 'youtube.com' in url or 'youtu.be' in url]\n",
        "        if youtube_urls:\n",
        "            video_id = extract_youtube_id(youtube_urls[0])\n",
        "            if video_id:\n",
        "                transcript = fetch_youtube_transcript(video_id, YOUTUBE_API_KEY)\n",
        "                if transcript:\n",
        "                    user_message += f\"\\n\\nTranscript of the YouTube video: {transcript}\"\n",
        "                else:\n",
        "                    user_message += \"\\n\\nTranscript of the YouTube video: Not available\"\n",
        "\n",
        "        state['messages'].append({\"role\": \"user\", \"content\": user_message})\n",
        "    state['needs_tool_call'] = False\n",
        "    return state\n",
        "\n",
        "def llm_node(state: State) -> State:\n",
        "    \"\"\"Calls the OpenAI LLM with the current messages and processes the response.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=state['messages'],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "    )\n",
        "    assistant_message = response.choices[0].message\n",
        "    state['messages'].append(assistant_message)\n",
        "\n",
        "    if assistant_message.tool_calls:\n",
        "        state['needs_tool_call'] = True\n",
        "    else:\n",
        "        state['final_response'] = assistant_message.content\n",
        "        state['needs_tool_call'] = False\n",
        "    return state\n",
        "\n",
        "def tool_node(state: State) -> State:\n",
        "    \"\"\"Executes tool calls and appends results to messages.\"\"\"\n",
        "    assistant_message = state['messages'][-1]\n",
        "    for tool_call in assistant_message.tool_calls:\n",
        "        result = execute_tool(tool_call)\n",
        "        state['messages'].append({\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": result,\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "        })\n",
        "    return state\n",
        "\n",
        "def output_node(state: State) -> State:\n",
        "    \"\"\"Prints the LLM's response.\"\"\"\n",
        "    print(\"Response:\", state['final_response'])\n",
        "    return state\n",
        "\n",
        "# Create the graph\n",
        "graph = Graph()\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"input\", input_node)\n",
        "graph.add_node(\"llm\", llm_node)\n",
        "graph.add_node(\"tool\", tool_node)\n",
        "graph.add_node(\"output\", output_node)\n",
        "\n",
        "# Define edges\n",
        "graph.add_edge(\"input\", \"llm\")\n",
        "graph.add_conditional_edges(\n",
        "    \"llm\",\n",
        "    lambda state: \"tool\" if state['needs_tool_call'] else \"output\",\n",
        "    {\"tool\": \"tool\", \"output\": \"output\"}\n",
        ")\n",
        "graph.add_edge(\"tool\", \"input\")\n",
        "graph.add_edge(\"output\", END)\n",
        "\n",
        "# Set entry point\n",
        "graph.set_entry_point(\"input\")\n",
        "\n",
        "# Compile the graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Run the workflow\n",
        "initial_state = {\n",
        "    \"messages\": [],\n",
        "    \"tool_calls\": [],\n",
        "    \"final_response\": \"\",\n",
        "    \"needs_tool_call\": False\n",
        "}\n",
        "result = app.invoke(initial_state)\n",
        "print(\"Final State:\", result)"
      ]
    }
  ]
}